<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.4//EN"
                  "http://www.oasis-open.org/docbook/xml/4.4/docbookx.dtd">
<article>
  <articleinfo>
    <title>Normality Tests</title>
    <author>
      <firstname>Rapport package team @</firstname>
      <surname>https://github.com/aL3xa/rapport</surname>
    </author>
    <date>2011-04-26 20:25 CET</date>
  </articleinfo>
<section id="description">
  <title>Description</title>
  <para>
    Overview of several normality tests and diagnostic plots that can
    screen departures from normality.
  </para>
</section>
<section id="introduction">
  <title>Introduction</title>
  <para>
    In statistics, <emphasis>normality</emphasis> refers to an
    assumption that the distribution of a random variable follows
    <emphasis>normal</emphasis> (<emphasis>Gaussian</emphasis>)
    distribution. Because of its bell-like shape, it's also known as the
    <emphasis>&quot;bell curve&quot;</emphasis>. The formula for
    <emphasis>normal distribution</emphasis> is:
  </para>
  <para>
    $f(x) = \frac{1}{\sqrt{2\pi{}\sigma{}^2}} e^{-\frac{(x-\mu{})^2}{2\sigma{}^2}}$
  </para>
  <para>
    <emphasis>Normal distribution</emphasis> belongs to a
    <emphasis>location-scale family</emphasis> of distributions, as it's
    defined two parameters:
  </para>
  <itemizedlist>
    <listitem>
      <para>
        <emphasis>μ</emphasis> - <emphasis>mean</emphasis> or
        <emphasis>expectation</emphasis> (location parameter)
      </para>
    </listitem>
    <listitem>
      <para>
        <emphasis>σ<superscript>2</superscript></emphasis> -
        <emphasis>variance</emphasis> (scale parameter)
      </para>
    </listitem>
  </itemizedlist>
  <para>
    <ulink url="806ea97c59e1a12d4acae4968957aaa9-hires.png"><inlinemediaobject>
      <imageobject>
        <imagedata fileref="806ea97c59e1a12d4acae4968957aaa9.png" />
      </imageobject>
    </inlinemediaobject></ulink>
  </para>
</section>
<section id="normality-tests">
  <title>Normality Tests</title>
  <section id="overview">
    <title>Overview</title>
    <para>
      Various hypothesis tests can be applied in order to test if the
      distribution of given random variable violates normality
      assumption. These procedures test the H<subscript>0</subscript>
      that provided variable's distribution is
      <emphasis>normal</emphasis>. At this point only few such tests
      will be covered: the ones that are available in
      <literal>stats</literal> package (which comes bundled with default
      R installation) and <literal>nortest</literal> package that is
      <ulink url="http://cran.r-project.org/web/packages/nortest/index.html">available</ulink>
      on CRAN.
    </para>
    <itemizedlist>
      <listitem>
        <para>
          <emphasis role="strong">Shapiro-Wilk test</emphasis> is a
          powerful normality test appropriate for small samples. In R,
          it's implemented in <literal>shapiro.test</literal> function
          available in <literal>stats</literal> package.
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="strong">Lilliefors test</emphasis> is a
          modification of <emphasis>Kolmogorov-Smirnov test</emphasis>
          appropriate for testing normality when parameters or normal
          distribution (<emphasis>μ</emphasis>,
          <emphasis>σ<superscript>2</superscript></emphasis>) are not
          known. <literal>lillie.test</literal> function is located in
          <literal>nortest</literal> package.
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="strong">Anderson-Darling test</emphasis> is
          one of the most powerful normality tests as it will detect the
          most of departures from normality. You can find
          <literal>ad.test</literal> function in
          <literal>nortest</literal> package.
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="strong">Pearson Χ<superscript>2</superscript>
          test</emphasis> is another normality test which takes more
          &quot;traditional&quot; approach in normality testing.
          <literal>pearson.test</literal> is located in
          <literal>nortest</literal> package.
        </para>
      </listitem>
    </itemizedlist>
  </section>
  <section id="results">
    <title>Results</title>
    <para>
      Here you can see the results of applied normality tests
      (<emphasis>p-values</emphasis> less than 0.05 indicate significant
      discrepancies):
    </para>
    <!-- endlist -->
    <informaltable>
      <tgroup cols="3">
        <colspec align="left" />
        <colspec align="left" />
        <colspec align="left" />
        <thead>
          <row>
            <entry>
            </entry>
            <entry>
              <emphasis role="strong">Statistic</emphasis>
            </entry>
            <entry>
              <emphasis role="strong">p-value</emphasis>
            </entry>
          </row>
        </thead>
        <tbody>
          <row>
            <entry>
              Shapiro-Wilk normality test
            </entry>
            <entry>
              0.9001
            </entry>
            <entry>
              0
            </entry>
          </row>
          <row>
            <entry>
              Lilliefors (Kolmogorov-Smirnov) normality test
            </entry>
            <entry>
              0.168
            </entry>
            <entry>
              0
            </entry>
          </row>
          <row>
            <entry>
              Anderson-Darling normality test
            </entry>
            <entry>
              18.753
            </entry>
            <entry>
              0
            </entry>
          </row>
          <row>
            <entry>
              Pearson chi-square normality test
            </entry>
            <entry>
              1791.25
            </entry>
            <entry>
              0
            </entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>
    <para>
      So, let's draw some conclusions based on applied normality test:
    </para>
    <itemizedlist>
      <listitem>
        <para>
          according to <emphasis>Shapiro-Wilk test</emphasis>, the
          distribution of <emphasis>Internet usage in leisure time
          (hours per day)</emphasis> is not normal.
        </para>
      </listitem>
      <listitem>
        <para>
          based on <emphasis>Lilliefors test</emphasis>, distribution of
          <emphasis>Internet usage in leisure time (hours per
          day)</emphasis> is not normal
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis>Anderson-Darling test</emphasis> confirms violation
          of normality assumption
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis>Pearson's Χ<superscript>2</superscript>
          test</emphasis> classifies the underlying distribution as
          normal
        </para>
      </listitem>
    </itemizedlist>
  </section>
</section>
<section id="diagnostic-plots">
  <title>Diagnostic Plots</title>
  <para>
    There are various plots that can help you decide about the normality
    of the distribution. Only a few most commonly used plots will be
    shown: <emphasis>histogram</emphasis>, <emphasis>Q-Q plot</emphasis>
    and <emphasis>kernel density plot</emphasis>.
  </para>
  <section id="histogram">
    <title>Histogram</title>
    <para>
      <emphasis>Histogram</emphasis> was first introduced by
      <emphasis>Karl Pearson</emphasis> and it's probably the most
      popular plot for depicting the probability distribution of a
      random variable. However, the decision depends on number of bins,
      so it can sometimes be misleading. If the variable distribution is
      normal, bins should resemble the &quot;bell-like&quot; shape.
    </para>
    <para>
      <ulink url="a949c4cf7eda15cd079e9d63b81acdd4-hires.png"><inlinemediaobject>
        <imageobject>
          <imagedata fileref="a949c4cf7eda15cd079e9d63b81acdd4.png" />
        </imageobject>
      </inlinemediaobject></ulink>
    </para>
  </section>
  <section id="q-q-plot">
    <title>Q-Q Plot</title>
    <para>
      &quot;Q&quot; in <emphasis>Q-Q plot</emphasis> stands for
      <emphasis>quantile</emphasis>, as this plot compares empirical and
      theoretical distribution (in this case,
      <emphasis>normal</emphasis> distribution) by plotting their
      quantiles against each other. For normal distribution, plotted
      dots should approximate a &quot;straight&quot;,
      <literal>x = y</literal> line.
    </para>
    <para>
      <ulink url="eecb9a780afd4dd0de9737991e467a6e-hires.png"><inlinemediaobject>
        <imageobject>
          <imagedata fileref="eecb9a780afd4dd0de9737991e467a6e.png" />
        </imageobject>
      </inlinemediaobject></ulink>
    </para>
  </section>
  <section id="kernel-density-plot">
    <title>Kernel Density Plot</title>
    <para>
      <emphasis>Kernel density plot</emphasis> is a plot of smoothed
      <emphasis>empirical distribution function</emphasis>. As such, it
      provides good insight about the shape of the distribution. For
      normal distributions, it should resemble the well known &quot;bell
      shape&quot;.
    </para>
    <para>
      <ulink url="fe4ddb2fb2ffd78d3c5448a9cc27a8de-hires.png"><inlinemediaobject>
        <imageobject>
          <imagedata fileref="fe4ddb2fb2ffd78d3c5448a9cc27a8de.png" />
        </imageobject>
      </inlinemediaobject></ulink>
    </para>
  </section>
</section>
<section id="description-1">
  <title>Description</title>
  <para>
    Overview of several normality tests and diagnostic plots that can
    screen departures from normality.
  </para>
</section>
<section id="introduction-1">
  <title>Introduction</title>
  <para>
    In statistics, <emphasis>normality</emphasis> refers to an
    assumption that the distribution of a random variable follows
    <emphasis>normal</emphasis> (<emphasis>Gaussian</emphasis>)
    distribution. Because of its bell-like shape, it's also known as the
    <emphasis>&quot;bell curve&quot;</emphasis>. The formula for
    <emphasis>normal distribution</emphasis> is:
  </para>
  <para>
    $f(x) = \frac{1}{\sqrt{2\pi{}\sigma{}^2}} e^{-\frac{(x-\mu{})^2}{2\sigma{}^2}}$
  </para>
  <para>
    <emphasis>Normal distribution</emphasis> belongs to a
    <emphasis>location-scale family</emphasis> of distributions, as it's
    defined two parameters:
  </para>
  <itemizedlist>
    <listitem>
      <para>
        <emphasis>μ</emphasis> - <emphasis>mean</emphasis> or
        <emphasis>expectation</emphasis> (location parameter)
      </para>
    </listitem>
    <listitem>
      <para>
        <emphasis>σ<superscript>2</superscript></emphasis> -
        <emphasis>variance</emphasis> (scale parameter)
      </para>
    </listitem>
  </itemizedlist>
</section>
<section id="normality-tests-1">
  <title>Normality Tests</title>
  <section id="overview-1">
    <title>Overview</title>
    <para>
      Various hypothesis tests can be applied in order to test if the
      distribution of given random variable violates normality
      assumption. These procedures test the H<subscript>0</subscript>
      that provided variable's distribution is
      <emphasis>normal</emphasis>. At this point only few such tests
      will be covered: the ones that are available in
      <literal>stats</literal> package (which comes bundled with default
      R installation) and <literal>nortest</literal> package that is
      <ulink url="http://cran.r-project.org/web/packages/nortest/index.html">available</ulink>
      on CRAN.
    </para>
    <itemizedlist>
      <listitem>
        <para>
          <emphasis role="strong">Shapiro-Wilk test</emphasis> is a
          powerful normality test appropriate for small samples. In R,
          it's implemented in <literal>shapiro.test</literal> function
          available in <literal>stats</literal> package.
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="strong">Lilliefors test</emphasis> is a
          modification of <emphasis>Kolmogorov-Smirnov test</emphasis>
          appropriate for testing normality when parameters or normal
          distribution (<emphasis>μ</emphasis>,
          <emphasis>σ<superscript>2</superscript></emphasis>) are not
          known. <literal>lillie.test</literal> function is located in
          <literal>nortest</literal> package.
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="strong">Anderson-Darling test</emphasis> is
          one of the most powerful normality tests as it will detect the
          most of departures from normality. You can find
          <literal>ad.test</literal> function in
          <literal>nortest</literal> package.
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="strong">Pearson Χ<superscript>2</superscript>
          test</emphasis> is another normality test which takes more
          &quot;traditional&quot; approach in normality testing.
          <literal>pearson.test</literal> is located in
          <literal>nortest</literal> package.
        </para>
      </listitem>
    </itemizedlist>
  </section>
  <section id="results-1">
    <title>Results</title>
    <para>
      Here you can see the results of applied normality tests
      (<emphasis>p-values</emphasis> less than 0.05 indicate significant
      discrepancies):
    </para>
    <!-- endlist -->
    <informaltable>
      <tgroup cols="3">
        <colspec align="left" />
        <colspec align="left" />
        <colspec align="left" />
        <thead>
          <row>
            <entry>
            </entry>
            <entry>
              <emphasis role="strong">Statistic</emphasis>
            </entry>
            <entry>
              <emphasis role="strong">p-value</emphasis>
            </entry>
          </row>
        </thead>
        <tbody>
          <row>
            <entry>
              Shapiro-Wilk normality test
            </entry>
            <entry>
              0.9001
            </entry>
            <entry>
              0
            </entry>
          </row>
          <row>
            <entry>
              Lilliefors (Kolmogorov-Smirnov) normality test
            </entry>
            <entry>
              0.168
            </entry>
            <entry>
              0
            </entry>
          </row>
          <row>
            <entry>
              Anderson-Darling normality test
            </entry>
            <entry>
              18.753
            </entry>
            <entry>
              0
            </entry>
          </row>
          <row>
            <entry>
              Pearson chi-square normality test
            </entry>
            <entry>
              1791.25
            </entry>
            <entry>
              0
            </entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>
    <para>
      So, let's draw some conclusions based on applied normality test:
    </para>
    <itemizedlist>
      <listitem>
        <para>
          according to <emphasis>Shapiro-Wilk test</emphasis>, the
          distribution of <emphasis>Internet usage in leisure time
          (hours per day)</emphasis> is not normal.
        </para>
      </listitem>
      <listitem>
        <para>
          based on <emphasis>Lilliefors test</emphasis>, distribution of
          <emphasis>Internet usage in leisure time (hours per
          day)</emphasis> is not normal
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis>Anderson-Darling test</emphasis> confirms violation
          of normality assumption
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis>Pearson's Χ<superscript>2</superscript>
          test</emphasis> classifies the underlying distribution as
          normal
        </para>
      </listitem>
    </itemizedlist>
  </section>
</section>
<section id="diagnostic-plots-1">
  <title>Diagnostic Plots</title>
  <para>
    There are various plots that can help you decide about the normality
    of the distribution. Only a few most commonly used plots will be
    shown: <emphasis>histogram</emphasis>, <emphasis>Q-Q plot</emphasis>
    and <emphasis>kernel density plot</emphasis>.
  </para>
  <section id="histogram-1">
    <title>Histogram</title>
    <para>
      <emphasis>Histogram</emphasis> was first introduced by
      <emphasis>Karl Pearson</emphasis> and it's probably the most
      popular plot for depicting the probability distribution of a
      random variable. However, the decision depends on number of bins,
      so it can sometimes be misleading. If the variable distribution is
      normal, bins should resemble the &quot;bell-like&quot; shape.
    </para>
    <para>
      <ulink url="a949c4cf7eda15cd079e9d63b81acdd4-hires.png"><inlinemediaobject>
        <imageobject>
          <imagedata fileref="a949c4cf7eda15cd079e9d63b81acdd4.png" />
        </imageobject>
      </inlinemediaobject></ulink>
    </para>
  </section>
  <section id="q-q-plot-1">
    <title>Q-Q Plot</title>
    <para>
      &quot;Q&quot; in <emphasis>Q-Q plot</emphasis> stands for
      <emphasis>quantile</emphasis>, as this plot compares empirical and
      theoretical distribution (in this case,
      <emphasis>normal</emphasis> distribution) by plotting their
      quantiles against each other. For normal distribution, plotted
      dots should approximate a &quot;straight&quot;,
      <literal>x = y</literal> line.
    </para>
    <para>
      <ulink url="eecb9a780afd4dd0de9737991e467a6e-hires.png"><inlinemediaobject>
        <imageobject>
          <imagedata fileref="eecb9a780afd4dd0de9737991e467a6e.png" />
        </imageobject>
      </inlinemediaobject></ulink>
    </para>
  </section>
  <section id="kernel-density-plot-1">
    <title>Kernel Density Plot</title>
    <para>
      <emphasis>Kernel density plot</emphasis> is a plot of smoothed
      <emphasis>empirical distribution function</emphasis>. As such, it
      provides good insight about the shape of the distribution. For
      normal distributions, it should resemble the well known &quot;bell
      shape&quot;.
    </para>
    <para>
      <ulink url="daf251be0fc0a31c9b51a510640ce60f-hires.png"><inlinemediaobject>
        <imageobject>
          <imagedata fileref="daf251be0fc0a31c9b51a510640ce60f.png" />
        </imageobject>
      </inlinemediaobject></ulink>
    </para>
  </section>
</section>
<section id="description-2">
  <title>Description</title>
  <para>
    Overview of several normality tests and diagnostic plots that can
    screen departures from normality.
  </para>
</section>
<section id="introduction-2">
  <title>Introduction</title>
  <para>
    In statistics, <emphasis>normality</emphasis> refers to an
    assumption that the distribution of a random variable follows
    <emphasis>normal</emphasis> (<emphasis>Gaussian</emphasis>)
    distribution. Because of its bell-like shape, it's also known as the
    <emphasis>&quot;bell curve&quot;</emphasis>. The formula for
    <emphasis>normal distribution</emphasis> is:
  </para>
  <para>
    $f(x) = \frac{1}{\sqrt{2\pi{}\sigma{}^2}} e^{-\frac{(x-\mu{})^2}{2\sigma{}^2}}$
  </para>
  <para>
    <emphasis>Normal distribution</emphasis> belongs to a
    <emphasis>location-scale family</emphasis> of distributions, as it's
    defined two parameters:
  </para>
  <itemizedlist>
    <listitem>
      <para>
        <emphasis>μ</emphasis> - <emphasis>mean</emphasis> or
        <emphasis>expectation</emphasis> (location parameter)
      </para>
    </listitem>
    <listitem>
      <para>
        <emphasis>σ<superscript>2</superscript></emphasis> -
        <emphasis>variance</emphasis> (scale parameter)
      </para>
    </listitem>
  </itemizedlist>
  <para>
    <ulink url="806ea97c59e1a12d4acae4968957aaa9-hires.png"><inlinemediaobject>
      <imageobject>
        <imagedata fileref="806ea97c59e1a12d4acae4968957aaa9.png" />
      </imageobject>
    </inlinemediaobject></ulink>
  </para>
</section>
<section id="normality-tests-2">
  <title>Normality Tests</title>
  <section id="overview-2">
    <title>Overview</title>
    <para>
      Various hypothesis tests can be applied in order to test if the
      distribution of given random variable violates normality
      assumption. These procedures test the H<subscript>0</subscript>
      that provided variable's distribution is
      <emphasis>normal</emphasis>. At this point only few such tests
      will be covered: the ones that are available in
      <literal>stats</literal> package (which comes bundled with default
      R installation) and <literal>nortest</literal> package that is
      <ulink url="http://cran.r-project.org/web/packages/nortest/index.html">available</ulink>
      on CRAN.
    </para>
    <itemizedlist>
      <listitem>
        <para>
          <emphasis role="strong">Shapiro-Wilk test</emphasis> is a
          powerful normality test appropriate for small samples. In R,
          it's implemented in <literal>shapiro.test</literal> function
          available in <literal>stats</literal> package.
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="strong">Lilliefors test</emphasis> is a
          modification of <emphasis>Kolmogorov-Smirnov test</emphasis>
          appropriate for testing normality when parameters or normal
          distribution (<emphasis>μ</emphasis>,
          <emphasis>σ<superscript>2</superscript></emphasis>) are not
          known. <literal>lillie.test</literal> function is located in
          <literal>nortest</literal> package.
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="strong">Anderson-Darling test</emphasis> is
          one of the most powerful normality tests as it will detect the
          most of departures from normality. You can find
          <literal>ad.test</literal> function in
          <literal>nortest</literal> package.
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="strong">Pearson Χ<superscript>2</superscript>
          test</emphasis> is another normality test which takes more
          &quot;traditional&quot; approach in normality testing.
          <literal>pearson.test</literal> is located in
          <literal>nortest</literal> package.
        </para>
      </listitem>
    </itemizedlist>
  </section>
  <section id="results-2">
    <title>Results</title>
    <para>
      Here you can see the results of applied normality tests
      (<emphasis>p-values</emphasis> less than 0.05 indicate significant
      discrepancies):
    </para>
    <!-- endlist -->
    <informaltable>
      <tgroup cols="3">
        <colspec align="left" />
        <colspec align="left" />
        <colspec align="left" />
        <thead>
          <row>
            <entry>
            </entry>
            <entry>
              <emphasis role="strong">Statistic</emphasis>
            </entry>
            <entry>
              <emphasis role="strong">p-value</emphasis>
            </entry>
          </row>
        </thead>
        <tbody>
          <row>
            <entry>
              Shapiro-Wilk normality test
            </entry>
            <entry>
              0.9001
            </entry>
            <entry>
              0
            </entry>
          </row>
          <row>
            <entry>
              Lilliefors (Kolmogorov-Smirnov) normality test
            </entry>
            <entry>
              0.168
            </entry>
            <entry>
              0
            </entry>
          </row>
          <row>
            <entry>
              Anderson-Darling normality test
            </entry>
            <entry>
              18.753
            </entry>
            <entry>
              0
            </entry>
          </row>
          <row>
            <entry>
              Pearson chi-square normality test
            </entry>
            <entry>
              1791.25
            </entry>
            <entry>
              0
            </entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>
    <para>
      So, let's draw some conclusions based on applied normality test:
    </para>
    <itemizedlist>
      <listitem>
        <para>
          according to <emphasis>Shapiro-Wilk test</emphasis>, the
          distribution of <emphasis>Internet usage in leisure time
          (hours per day)</emphasis> is not normal.
        </para>
      </listitem>
      <listitem>
        <para>
          based on <emphasis>Lilliefors test</emphasis>, distribution of
          <emphasis>Internet usage in leisure time (hours per
          day)</emphasis> is not normal
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis>Anderson-Darling test</emphasis> confirms violation
          of normality assumption
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis>Pearson's Χ<superscript>2</superscript>
          test</emphasis> classifies the underlying distribution as
          normal
        </para>
      </listitem>
    </itemizedlist>
  </section>
</section>
<section id="diagnostic-plots-2">
  <title>Diagnostic Plots</title>
  <para>
    There are various plots that can help you decide about the normality
    of the distribution. Only a few most commonly used plots will be
    shown: <emphasis>histogram</emphasis>, <emphasis>Q-Q plot</emphasis>
    and <emphasis>kernel density plot</emphasis>.
  </para>
  <section id="histogram-2">
    <title>Histogram</title>
    <para>
      <emphasis>Histogram</emphasis> was first introduced by
      <emphasis>Karl Pearson</emphasis> and it's probably the most
      popular plot for depicting the probability distribution of a
      random variable. However, the decision depends on number of bins,
      so it can sometimes be misleading. If the variable distribution is
      normal, bins should resemble the &quot;bell-like&quot; shape.
    </para>
    <para>
      <ulink url="a949c4cf7eda15cd079e9d63b81acdd4-hires.png"><inlinemediaobject>
        <imageobject>
          <imagedata fileref="a949c4cf7eda15cd079e9d63b81acdd4.png" />
        </imageobject>
      </inlinemediaobject></ulink>
    </para>
  </section>
  <section id="q-q-plot-2">
    <title>Q-Q Plot</title>
    <para>
      &quot;Q&quot; in <emphasis>Q-Q plot</emphasis> stands for
      <emphasis>quantile</emphasis>, as this plot compares empirical and
      theoretical distribution (in this case,
      <emphasis>normal</emphasis> distribution) by plotting their
      quantiles against each other. For normal distribution, plotted
      dots should approximate a &quot;straight&quot;,
      <literal>x = y</literal> line.
    </para>
    <para>
      <ulink url="95d42d4d0934008cfa630e1c4523e09a-hires.png"><inlinemediaobject>
        <imageobject>
          <imagedata fileref="95d42d4d0934008cfa630e1c4523e09a.png" />
        </imageobject>
      </inlinemediaobject></ulink>
    </para>
  </section>
  <section id="kernel-density-plot-2">
    <title>Kernel Density Plot</title>
    <para>
      <emphasis>Kernel density plot</emphasis> is a plot of smoothed
      <emphasis>empirical distribution function</emphasis>. As such, it
      provides good insight about the shape of the distribution. For
      normal distributions, it should resemble the well known &quot;bell
      shape&quot;.
    </para>
    <para>
      <ulink url="db1e16796e7e791e46cc0c0ca2f68bab-hires.png"><inlinemediaobject>
        <imageobject>
          <imagedata fileref="db1e16796e7e791e46cc0c0ca2f68bab.png" />
        </imageobject>
      </inlinemediaobject></ulink>
    </para>
    <para>
      This report was generated with
      <ulink url="http://www.r-project.org/">R</ulink> (2.14.0) and
      <ulink url="http://al3xa.github.com/rapport/">rapport</ulink>
      (0.2) in 2.928 sec on x86_64-unknown-linux-gnu platform.
    </para>
    <figure>
      <title></title>
      <mediaobject>
        <imageobject>
          <imagedata fileref="images/logo.png" />
        </imageobject>
        <textobject><phrase></phrase></textobject>
      </mediaobject>
    </figure>
  </section>
</section>
</article>
