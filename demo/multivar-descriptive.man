.\"t
.TH Descriptive "" "2011\[en]04\[en]26 20:25 CET" "statistics"
.SS Description
.PP
This template will return descriptive statistics of numerical or
frequency tables of categorical variables.
.SS \f[I]gender\f[] (\[lq]Gender\[rq])
.PP
The dataset has \f[I]709\f[] observations with \f[I]673\f[] valid values
(missing: \f[I]36\f[]) in \f[I]gender\f[] (\[lq]Gender\[rq]).
This variable seems to be a factor.
.SS Base statistics
.PP
.TS
tab(@);
l l l l l l.
T{
T}@T{
\f[B]gender\f[]
T}@T{
\f[B]N\f[]
T}@T{
\f[B]pct\f[]
T}@T{
\f[B]cumul.count\f[]
T}@T{
\f[B]cumul.pct\f[]
T}
_
T{
1
T}@T{
male
T}@T{
410
T}@T{
60.9212
T}@T{
410
T}@T{
60.9212
T}
T{
2
T}@T{
female
T}@T{
263
T}@T{
39.0788
T}@T{
673
T}@T{
100
T}
T{
Total
T}@T{
T}@T{
673
T}@T{
100
T}@T{
673
T}@T{
100
T}
.TE
.SS Barplot
.PP
[IMAGE: image (3ed92ab3ffc6e875335e7e8c774c35a8.png)]
.PP
It seems that the highest value is \f[I]2\f[] which is exactly 2 times
higher than the smallest value (\f[I]1\f[]).
.SS \f[I]age\f[] (\[lq]Age\[rq])
.PP
The dataset has \f[I]709\f[] observations with \f[I]677\f[] valid values
(missing: \f[I]32\f[]) in \f[I]age\f[] (\[lq]Age\[rq]).
This variable seems to be numeric.
.SS Base statistics
.PP
.TS
tab(@);
l l l l.
T{
\f[B]value\f[]
T}@T{
\f[B]mean(age)\f[]
T}@T{
\f[B]sd(age)\f[]
T}@T{
\f[B]var(age)\f[]
T}
_
T{
(all)
T}@T{
24.5731
T}@T{
6.8491
T}@T{
46.9107
T}
.TE
.SS Histogram
.PP
[IMAGE: image (ac5d789145bdef09b10219ef16429f53.png)]
.PP
It seems that the highest value is \f[I]58\f[] which is exactly 3.625
times higher than the smallest value (\f[I]16\f[]).
.PP
The standard deviation is 6.8491 (variance: 46.9107).
The expected value is around 24.5731, somewhere between 24.0572 and
25.0891 (SE: 0.2632).
.PP
If we suppose that \f[I]Age\f[] is not near to a normal distribution
(test: see below, skewness: 1.9296, kurtosis: 7.4851), checking the
median (23) might be a better option instead of the mean.
The interquartile range (6) measures the statistics dispersion of the
variable (similar to standard deviation) based on median.
.SS Normality tests
.SS Introduction
.PP
In statistics, \f[I]normality\f[] refers to an assumption that the
distribution of a random variable follows \f[I]normal\f[]
(\f[I]Gaussian\f[]) distribution.
Because of its bell-like shape, it's also known as the \f[I]\[lq]bell
curve\[rq]\f[].
The formula for \f[I]normal distribution\f[] is:
.PP
.RS
$f(x) = \\frac{1}{\\sqrt{2\\pi{}\\sigma{}^2}} e^{-\\frac{(x-\\mu{})^2}{2\\sigma{}^2}}$
.RE
.PP
\f[I]Normal distribution\f[] belongs to a \f[I]location-scale family\f[]
of distributions, as it's defined two parameters:
.IP \[bu] 2
\f[I]μ\f[] - \f[I]mean\f[] or \f[I]expectation\f[] (location parameter)
.IP \[bu] 2
\f[I]σ^2^\f[] - \f[I]variance\f[] (scale parameter)
.PP
[IMAGE: image (2f8c434e103f36ec70966b372838d448.png)]
.SS Normality Tests
.SS Overview
.PP
Various hypothesis tests can be applied in order to test if the
distribution of given random variable violates normality assumption.
These procedures test the H~0~ that provided variable's distribution is
\f[I]normal\f[].
At this point only few such tests will be covered: the ones that are
available in \f[C]stats\f[] package (which comes bundled with default R
installation) and \f[C]nortest\f[] package that is
available (http://cran.r-project.org/web/packages/nortest/index.html) on
CRAN.
.IP \[bu] 2
\f[B]Shapiro-Wilk test\f[] is a powerful normality test appropriate for
small samples.
In R, it's implemented in \f[C]shapiro.test\f[] function available in
\f[C]stats\f[] package.
.IP \[bu] 2
\f[B]Lilliefors test\f[] is a modification of \f[I]Kolmogorov-Smirnov
test\f[] appropriate for testing normality when parameters or normal
distribution (\f[I]μ\f[], \f[I]σ^2^\f[]) are not known.
\f[C]lillie.test\f[] function is located in \f[C]nortest\f[] package.
.IP \[bu] 2
\f[B]Anderson-Darling test\f[] is one of the most powerful normality
tests as it will detect the most of departures from normality.
You can find \f[C]ad.test\f[] function in \f[C]nortest\f[] package.
.IP \[bu] 2
\f[B]Pearson Χ^2^ test\f[] is another normality test which takes more
\[lq]traditional\[rq] approach in normality testing.
\f[C]pearson.test\f[] is located in \f[C]nortest\f[] package.
.SS Results
.PP
Here you can see the results of applied normality tests
(\f[I]p-values\f[] less than 0.05 indicate significant discrepancies):
.PP
.TS
tab(@);
l l l.
T{
T}@T{
\f[B]H\f[]
T}@T{
\f[B]p\f[]
T}
_
T{
shapiro.test
T}@T{
0.8216
T}@T{
0
T}
T{
lillie.test
T}@T{
0.17
T}@T{
0
T}
T{
ad.test
T}@T{
32.1645
T}@T{
0
T}
T{
pearson.test
T}@T{
625.8479
T}@T{
0
T}
.TE
.PP
So, let's draw some conclusions based on applied normality test:
.IP \[bu] 2
according to \f[I]Shapiro-Wilk test\f[], the distribution of
\f[I]Age\f[] is not normal.
.IP \[bu] 2
based on \f[I]Lilliefors test\f[], distribution of \f[I]Age\f[] is not
normal
.IP \[bu] 2
\f[I]Anderson-Darling test\f[] confirms violation of normality
assumption
.IP \[bu] 2
\f[I]Pearson's Χ^2^ test\f[] classifies the underlying distribution as
non-normal
.SS Diagnostic Plots
.PP
There are various plots that can help you decide about the normality of
the distribution.
Only a few most commonly used plots will be shown: \f[I]histogram\f[],
\f[I]Q-Q plot\f[] and \f[I]kernel density plot\f[].
.SS Histogram
.PP
\f[I]Histogram\f[] was first introduced by \f[I]Karl Pearson\f[] and
it's probably the most popular plot for depicting the probability
distribution of a random variable.
However, the decision depends on number of bins, so it can sometimes be
misleading.
If the variable distribution is normal, bins should resemble the
\[lq]bell-like\[rq] shape.
.PP
[IMAGE: image (ac5d789145bdef09b10219ef16429f53.png)]
.SS Q-Q Plot
.PP
\[lq]Q\[rq] in \f[I]Q-Q plot\f[] stands for \f[I]quantile\f[], as this
plot compares empirical and theoretical distribution (in this case,
\f[I]normal\f[] distribution) by plotting their quantiles against each
other.
For normal distribution, plotted dots should approximate a
\[lq]straight\[rq], \f[C]x\ =\ y\f[] line.
.PP
[IMAGE: image (cbbba756d844aa053998959b73b9feff.png)]
.SS Kernel Density Plot
.PP
\f[I]Kernel density plot\f[] is a plot of smoothed \f[I]empirical
distribution function\f[].
As such, it provides good insight about the shape of the distribution.
For normal distributions, it should resemble the well known \[lq]bell
shape\[rq].
.PP
[IMAGE: image (6fd0494eea748495baa80653752f194f.png)]
.SS Description
.PP
This template will return descriptive statistics of numerical or
frequency tables of categorical variables.
.SS \f[I]chatim\f[] (\[lq]Chat & IM usage\[rq])
.PP
The dataset has \f[I]709\f[] observations with \f[I]669\f[] valid values
(missing: \f[I]40\f[]) in \f[I]chatim\f[] (\[lq]Chat & IM usage\[rq]).
This variable seems to be a factor.
.SS Base statistics
.PP
.TS
tab(@);
l l l l l l.
T{
T}@T{
\f[B]chatim\f[]
T}@T{
\f[B]N\f[]
T}@T{
\f[B]pct\f[]
T}@T{
\f[B]cumul.count\f[]
T}@T{
\f[B]cumul.pct\f[]
T}
_
T{
1
T}@T{
never
T}@T{
60
T}@T{
8.9686
T}@T{
60
T}@T{
8.9686
T}
T{
2
T}@T{
very rarely
T}@T{
73
T}@T{
10.9118
T}@T{
133
T}@T{
19.8804
T}
T{
3
T}@T{
rarely
T}@T{
58
T}@T{
8.6697
T}@T{
191
T}@T{
28.5501
T}
T{
4
T}@T{
sometimes
T}@T{
113
T}@T{
16.8909
T}@T{
304
T}@T{
45.441
T}
T{
5
T}@T{
often
T}@T{
136
T}@T{
20.3288
T}@T{
440
T}@T{
65.7698
T}
T{
6
T}@T{
very often
T}@T{
88
T}@T{
13.154
T}@T{
528
T}@T{
78.9238
T}
T{
7
T}@T{
always
T}@T{
141
T}@T{
21.0762
T}@T{
669
T}@T{
100
T}
T{
Total
T}@T{
T}@T{
669
T}@T{
100
T}@T{
669
T}@T{
100
T}
.TE
.SS Barplot
.PP
[IMAGE: image (5a00abbe4c793ceedbbf10939665b5cf.png)]
.PP
It seems that the highest value is \f[I]7\f[] which is exactly 7 times
higher than the smallest value (\f[I]1\f[]).
.SS \f[I]game\f[] (\[lq]On-line games usage\[rq])
.PP
The dataset has \f[I]709\f[] observations with \f[I]677\f[] valid values
(missing: \f[I]32\f[]) in \f[I]game\f[] (\[lq]On-line games usage\[rq]).
This variable seems to be a factor.
.SS Base statistics
.PP
.TS
tab(@);
l l l l l l.
T{
T}@T{
\f[B]game\f[]
T}@T{
\f[B]N\f[]
T}@T{
\f[B]pct\f[]
T}@T{
\f[B]cumul.count\f[]
T}@T{
\f[B]cumul.pct\f[]
T}
_
T{
1
T}@T{
never
T}@T{
352
T}@T{
51.9941
T}@T{
352
T}@T{
51.9941
T}
T{
2
T}@T{
very rarely
T}@T{
128
T}@T{
18.9069
T}@T{
480
T}@T{
70.901
T}
T{
3
T}@T{
rarely
T}@T{
32
T}@T{
4.7267
T}@T{
512
T}@T{
75.6278
T}
T{
4
T}@T{
sometimes
T}@T{
60
T}@T{
8.8626
T}@T{
572
T}@T{
84.4904
T}
T{
5
T}@T{
often
T}@T{
37
T}@T{
5.4653
T}@T{
609
T}@T{
89.9557
T}
T{
6
T}@T{
very often
T}@T{
35
T}@T{
5.1699
T}@T{
644
T}@T{
95.1256
T}
T{
7
T}@T{
always
T}@T{
33
T}@T{
4.8744
T}@T{
677
T}@T{
100
T}
T{
Total
T}@T{
T}@T{
677
T}@T{
100
T}@T{
677
T}@T{
100
T}
.TE
.SS Barplot
.PP
[IMAGE: image (e53046a09491443064e085131e547971.png)]
.PP
It seems that the highest value is \f[I]7\f[] which is exactly 7 times
higher than the smallest value (\f[I]1\f[]).
.SS \f[I]surf\f[] (\[lq]Web surfing usage\[rq])
.PP
The dataset has \f[I]709\f[] observations with \f[I]678\f[] valid values
(missing: \f[I]31\f[]) in \f[I]surf\f[] (\[lq]Web surfing usage\[rq]).
This variable seems to be a factor.
.SS Base statistics
.PP
.TS
tab(@);
l l l l l l.
T{
T}@T{
\f[B]surf\f[]
T}@T{
\f[B]N\f[]
T}@T{
\f[B]pct\f[]
T}@T{
\f[B]cumul.count\f[]
T}@T{
\f[B]cumul.pct\f[]
T}
_
T{
1
T}@T{
never
T}@T{
17
T}@T{
2.5074
T}@T{
17
T}@T{
2.5074
T}
T{
2
T}@T{
very rarely
T}@T{
26
T}@T{
3.8348
T}@T{
43
T}@T{
6.3422
T}
T{
3
T}@T{
rarely
T}@T{
33
T}@T{
4.8673
T}@T{
76
T}@T{
11.2094
T}
T{
4
T}@T{
sometimes
T}@T{
107
T}@T{
15.7817
T}@T{
183
T}@T{
26.9912
T}
T{
5
T}@T{
often
T}@T{
158
T}@T{
23.3038
T}@T{
341
T}@T{
50.295
T}
T{
6
T}@T{
very often
T}@T{
142
T}@T{
20.944
T}@T{
483
T}@T{
71.2389
T}
T{
7
T}@T{
always
T}@T{
195
T}@T{
28.7611
T}@T{
678
T}@T{
100
T}
T{
Total
T}@T{
T}@T{
678
T}@T{
100
T}@T{
678
T}@T{
100
T}
.TE
.SS Barplot
.PP
[IMAGE: image (0166a8b5df2f3db871e8736bfee8af6e.png)]
.PP
It seems that the highest value is \f[I]7\f[] which is exactly 7 times
higher than the smallest value (\f[I]1\f[]).
.SS \f[I]email\f[] (\[lq]Email usage\[rq])
.PP
The dataset has \f[I]709\f[] observations with \f[I]672\f[] valid values
(missing: \f[I]37\f[]) in \f[I]email\f[] (\[lq]Email usage\[rq]).
This variable seems to be a factor.
.SS Base statistics
.PP
.TS
tab(@);
l l l l l l.
T{
T}@T{
\f[B]email\f[]
T}@T{
\f[B]N\f[]
T}@T{
\f[B]pct\f[]
T}@T{
\f[B]cumul.count\f[]
T}@T{
\f[B]cumul.pct\f[]
T}
_
T{
1
T}@T{
never
T}@T{
13
T}@T{
1.9345
T}@T{
13
T}@T{
1.9345
T}
T{
2
T}@T{
very rarely
T}@T{
36
T}@T{
5.3571
T}@T{
49
T}@T{
7.2917
T}
T{
3
T}@T{
rarely
T}@T{
46
T}@T{
6.8452
T}@T{
95
T}@T{
14.1369
T}
T{
4
T}@T{
sometimes
T}@T{
87
T}@T{
12.9464
T}@T{
182
T}@T{
27.0833
T}
T{
5
T}@T{
often
T}@T{
123
T}@T{
18.3036
T}@T{
305
T}@T{
45.3869
T}
T{
6
T}@T{
very often
T}@T{
108
T}@T{
16.0714
T}@T{
413
T}@T{
61.4583
T}
T{
7
T}@T{
always
T}@T{
259
T}@T{
38.5417
T}@T{
672
T}@T{
100
T}
T{
Total
T}@T{
T}@T{
672
T}@T{
100
T}@T{
672
T}@T{
100
T}
.TE
.SS Barplot
.PP
[IMAGE: image (895cde198b269bf65b01e1e067a515c8.png)]
.PP
It seems that the highest value is \f[I]7\f[] which is exactly 7 times
higher than the smallest value (\f[I]1\f[]).
.SS \f[I]download\f[] (\[lq]Download usage\[rq])
.PP
The dataset has \f[I]709\f[] observations with \f[I]677\f[] valid values
(missing: \f[I]32\f[]) in \f[I]download\f[] (\[lq]Download usage\[rq]).
This variable seems to be a factor.
.SS Base statistics
.PP
.TS
tab(@);
l l l l l l.
T{
T}@T{
\f[B]download\f[]
T}@T{
\f[B]N\f[]
T}@T{
\f[B]pct\f[]
T}@T{
\f[B]cumul.count\f[]
T}@T{
\f[B]cumul.pct\f[]
T}
_
T{
1
T}@T{
never
T}@T{
11
T}@T{
1.6248
T}@T{
11
T}@T{
1.6248
T}
T{
2
T}@T{
very rarely
T}@T{
28
T}@T{
4.1359
T}@T{
39
T}@T{
5.7607
T}
T{
3
T}@T{
rarely
T}@T{
29
T}@T{
4.2836
T}@T{
68
T}@T{
10.0443
T}
T{
4
T}@T{
sometimes
T}@T{
80
T}@T{
11.8168
T}@T{
148
T}@T{
21.8612
T}
T{
5
T}@T{
often
T}@T{
124
T}@T{
18.3161
T}@T{
272
T}@T{
40.1773
T}
T{
6
T}@T{
very often
T}@T{
160
T}@T{
23.6337
T}@T{
432
T}@T{
63.8109
T}
T{
7
T}@T{
always
T}@T{
245
T}@T{
36.1891
T}@T{
677
T}@T{
100
T}
T{
Total
T}@T{
T}@T{
677
T}@T{
100
T}@T{
677
T}@T{
100
T}
.TE
.SS Barplot
.PP
[IMAGE: image (dde181184885b8777d0248b3f421289a.png)]
.PP
It seems that the highest value is \f[I]7\f[] which is exactly 7 times
higher than the smallest value (\f[I]1\f[]).
.SS \f[I]forum\f[] (\[lq]Web forums usage\[rq])
.PP
The dataset has \f[I]709\f[] observations with \f[I]673\f[] valid values
(missing: \f[I]36\f[]) in \f[I]forum\f[] (\[lq]Web forums usage\[rq]).
This variable seems to be a factor.
.SS Base statistics
.PP
.TS
tab(@);
l l l l l l.
T{
T}@T{
\f[B]forum\f[]
T}@T{
\f[B]N\f[]
T}@T{
\f[B]pct\f[]
T}@T{
\f[B]cumul.count\f[]
T}@T{
\f[B]cumul.pct\f[]
T}
_
T{
1
T}@T{
never
T}@T{
76
T}@T{
11.2927
T}@T{
76
T}@T{
11.2927
T}
T{
2
T}@T{
very rarely
T}@T{
80
T}@T{
11.8871
T}@T{
156
T}@T{
23.1798
T}
T{
3
T}@T{
rarely
T}@T{
72
T}@T{
10.6984
T}@T{
228
T}@T{
33.8782
T}
T{
4
T}@T{
sometimes
T}@T{
111
T}@T{
16.4933
T}@T{
339
T}@T{
50.3715
T}
T{
5
T}@T{
often
T}@T{
109
T}@T{
16.1961
T}@T{
448
T}@T{
66.5676
T}
T{
6
T}@T{
very often
T}@T{
119
T}@T{
17.682
T}@T{
567
T}@T{
84.2496
T}
T{
7
T}@T{
always
T}@T{
106
T}@T{
15.7504
T}@T{
673
T}@T{
100
T}
T{
Total
T}@T{
T}@T{
673
T}@T{
100
T}@T{
673
T}@T{
100
T}
.TE
.SS Barplot
.PP
[IMAGE: image (ac419134b2f4695e544d8886ba12e0c2.png)]
.PP
It seems that the highest value is \f[I]7\f[] which is exactly 7 times
higher than the smallest value (\f[I]1\f[]).
.SS \f[I]socnet\f[] (\[lq]Social networks usage\[rq])
.PP
The dataset has \f[I]709\f[] observations with \f[I]678\f[] valid values
(missing: \f[I]31\f[]) in \f[I]socnet\f[] (\[lq]Social networks
usage\[rq]).
This variable seems to be a factor.
.SS Base statistics
.PP
.TS
tab(@);
l l l l l l.
T{
T}@T{
\f[B]socnet\f[]
T}@T{
\f[B]N\f[]
T}@T{
\f[B]pct\f[]
T}@T{
\f[B]cumul.count\f[]
T}@T{
\f[B]cumul.pct\f[]
T}
_
T{
1
T}@T{
never
T}@T{
208
T}@T{
30.6785
T}@T{
208
T}@T{
30.6785
T}
T{
2
T}@T{
very rarely
T}@T{
102
T}@T{
15.0442
T}@T{
310
T}@T{
45.7227
T}
T{
3
T}@T{
rarely
T}@T{
57
T}@T{
8.4071
T}@T{
367
T}@T{
54.1298
T}
T{
4
T}@T{
sometimes
T}@T{
87
T}@T{
12.8319
T}@T{
454
T}@T{
66.9617
T}
T{
5
T}@T{
often
T}@T{
79
T}@T{
11.6519
T}@T{
533
T}@T{
78.6136
T}
T{
6
T}@T{
very often
T}@T{
80
T}@T{
11.7994
T}@T{
613
T}@T{
90.413
T}
T{
7
T}@T{
always
T}@T{
65
T}@T{
9.587
T}@T{
678
T}@T{
100
T}
T{
Total
T}@T{
T}@T{
678
T}@T{
100
T}@T{
678
T}@T{
100
T}
.TE
.SS Barplot
.PP
[IMAGE: image (8475d98870c1cdd2436a3abdb0d69a66.png)]
.PP
It seems that the highest value is \f[I]7\f[] which is exactly 7 times
higher than the smallest value (\f[I]1\f[]).
.SS \f[I]xxx\f[] (\[lq]Adult sites usage\[rq])
.PP
The dataset has \f[I]709\f[] observations with \f[I]674\f[] valid values
(missing: \f[I]35\f[]) in \f[I]xxx\f[] (\[lq]Adult sites usage\[rq]).
This variable seems to be a factor.
.SS Base statistics
.PP
.TS
tab(@);
l l l l l l.
T{
T}@T{
\f[B]xxx\f[]
T}@T{
\f[B]N\f[]
T}@T{
\f[B]pct\f[]
T}@T{
\f[B]cumul.count\f[]
T}@T{
\f[B]cumul.pct\f[]
T}
_
T{
1
T}@T{
never
T}@T{
274
T}@T{
40.6528
T}@T{
274
T}@T{
40.6528
T}
T{
2
T}@T{
very rarely
T}@T{
124
T}@T{
18.3976
T}@T{
398
T}@T{
59.0504
T}
T{
3
T}@T{
rarely
T}@T{
52
T}@T{
7.7151
T}@T{
450
T}@T{
66.7656
T}
T{
4
T}@T{
sometimes
T}@T{
131
T}@T{
19.4362
T}@T{
581
T}@T{
86.2018
T}
T{
5
T}@T{
often
T}@T{
46
T}@T{
6.8249
T}@T{
627
T}@T{
93.0267
T}
T{
6
T}@T{
very often
T}@T{
28
T}@T{
4.1543
T}@T{
655
T}@T{
97.181
T}
T{
7
T}@T{
always
T}@T{
19
T}@T{
2.819
T}@T{
674
T}@T{
100
T}
T{
Total
T}@T{
T}@T{
674
T}@T{
100
T}@T{
674
T}@T{
100
T}
.TE
.SS Barplot
.PP
[IMAGE: image (4fda8cf992e8de93624c45ef3c72a0c5.png)]
.PP
It seems that the highest value is \f[I]7\f[] which is exactly 7 times
higher than the smallest value (\f[I]1\f[]).
.SS Description
.PP
This template will return descriptive statistics of numerical or
frequency tables of categorical variables.
.SS \f[I]hp\f[]
.PP
The dataset has \f[I]32\f[] observations with \f[I]32\f[] valid values
(missing: \f[I]0\f[]) in \f[I]hp\f[].
This variable seems to be numeric.
.SS Base statistics
.PP
.TS
tab(@);
l l l l.
T{
\f[B]value\f[]
T}@T{
\f[B]mean(hp)\f[]
T}@T{
\f[B]sd(hp)\f[]
T}@T{
\f[B]var(hp)\f[]
T}
_
T{
(all)
T}@T{
146.6875
T}@T{
68.5629
T}@T{
4700.8669
T}
.TE
.SS Histogram
.PP
[IMAGE: image (d90ec4a0af55fabeae7988710a062ce0.png)]
.PP
It seems that the highest value is \f[I]335\f[] which is exactly 6.4423
times higher than the smallest value (\f[I]52\f[]).
.PP
The standard deviation is 68.5629 (variance: 4700.8669).
The expected value is around 146.6875, somewhere between 122.9317 and
170.4433 (SE: 12.1203).
.PP
If we suppose that \f[I]hp\f[] is not near to a normal distribution
(test: see below, skewness: 0.7614, kurtosis: 3.0522), checking the
median (123) might be a better option instead of the mean.
The interquartile range (83.5) measures the statistics dispersion of the
variable (similar to standard deviation) based on median.
.SS Normality tests
.SS Introduction
.PP
In statistics, \f[I]normality\f[] refers to an assumption that the
distribution of a random variable follows \f[I]normal\f[]
(\f[I]Gaussian\f[]) distribution.
Because of its bell-like shape, it's also known as the \f[I]\[lq]bell
curve\[rq]\f[].
The formula for \f[I]normal distribution\f[] is:
.PP
.RS
$f(x) = \\frac{1}{\\sqrt{2\\pi{}\\sigma{}^2}} e^{-\\frac{(x-\\mu{})^2}{2\\sigma{}^2}}$
.RE
.PP
\f[I]Normal distribution\f[] belongs to a \f[I]location-scale family\f[]
of distributions, as it's defined two parameters:
.IP \[bu] 2
\f[I]μ\f[] - \f[I]mean\f[] or \f[I]expectation\f[] (location parameter)
.IP \[bu] 2
\f[I]σ^2^\f[] - \f[I]variance\f[] (scale parameter)
.PP
[IMAGE: image (2f8c434e103f36ec70966b372838d448.png)]
.SS Normality Tests
.SS Overview
.PP
Various hypothesis tests can be applied in order to test if the
distribution of given random variable violates normality assumption.
These procedures test the H~0~ that provided variable's distribution is
\f[I]normal\f[].
At this point only few such tests will be covered: the ones that are
available in \f[C]stats\f[] package (which comes bundled with default R
installation) and \f[C]nortest\f[] package that is
available (http://cran.r-project.org/web/packages/nortest/index.html) on
CRAN.
.IP \[bu] 2
\f[B]Shapiro-Wilk test\f[] is a powerful normality test appropriate for
small samples.
In R, it's implemented in \f[C]shapiro.test\f[] function available in
\f[C]stats\f[] package.
.IP \[bu] 2
\f[B]Lilliefors test\f[] is a modification of \f[I]Kolmogorov-Smirnov
test\f[] appropriate for testing normality when parameters or normal
distribution (\f[I]μ\f[], \f[I]σ^2^\f[]) are not known.
\f[C]lillie.test\f[] function is located in \f[C]nortest\f[] package.
.IP \[bu] 2
\f[B]Anderson-Darling test\f[] is one of the most powerful normality
tests as it will detect the most of departures from normality.
You can find \f[C]ad.test\f[] function in \f[C]nortest\f[] package.
.IP \[bu] 2
\f[B]Pearson Χ^2^ test\f[] is another normality test which takes more
\[lq]traditional\[rq] approach in normality testing.
\f[C]pearson.test\f[] is located in \f[C]nortest\f[] package.
.SS Results
.PP
Here you can see the results of applied normality tests
(\f[I]p-values\f[] less than 0.05 indicate significant discrepancies):
.PP
.TS
tab(@);
l l l.
T{
T}@T{
\f[B]H\f[]
T}@T{
\f[B]p\f[]
T}
_
T{
shapiro.test
T}@T{
0.9334
T}@T{
0.0488
T}
T{
lillie.test
T}@T{
0.1664
T}@T{
0.0245
T}
T{
ad.test
T}@T{
0.7077
T}@T{
0.0584
T}
T{
pearson.test
T}@T{
11.5
T}@T{
0.0423
T}
.TE
.PP
So, let's draw some conclusions based on applied normality test:
.IP \[bu] 2
according to \f[I]Shapiro-Wilk test\f[], the distribution of \f[I]hp\f[]
is not normal.
.IP \[bu] 2
based on \f[I]Lilliefors test\f[], distribution of \f[I]hp\f[] is not
normal
.IP \[bu] 2
\f[I]Anderson-Darling test\f[] confirms normality assumption
.IP \[bu] 2
\f[I]Pearson's Χ^2^ test\f[] classifies the underlying distribution as
non-normal
.SS Diagnostic Plots
.PP
There are various plots that can help you decide about the normality of
the distribution.
Only a few most commonly used plots will be shown: \f[I]histogram\f[],
\f[I]Q-Q plot\f[] and \f[I]kernel density plot\f[].
.SS Histogram
.PP
\f[I]Histogram\f[] was first introduced by \f[I]Karl Pearson\f[] and
it's probably the most popular plot for depicting the probability
distribution of a random variable.
However, the decision depends on number of bins, so it can sometimes be
misleading.
If the variable distribution is normal, bins should resemble the
\[lq]bell-like\[rq] shape.
.PP
[IMAGE: image (d90ec4a0af55fabeae7988710a062ce0.png)]
.SS Q-Q Plot
.PP
\[lq]Q\[rq] in \f[I]Q-Q plot\f[] stands for \f[I]quantile\f[], as this
plot compares empirical and theoretical distribution (in this case,
\f[I]normal\f[] distribution) by plotting their quantiles against each
other.
For normal distribution, plotted dots should approximate a
\[lq]straight\[rq], \f[C]x\ =\ y\f[] line.
.PP
[IMAGE: image (17e5c77b83c6e3e636487406decc14c7.png)]
.SS Kernel Density Plot
.PP
\f[I]Kernel density plot\f[] is a plot of smoothed \f[I]empirical
distribution function\f[].
As such, it provides good insight about the shape of the distribution.
For normal distributions, it should resemble the well known \[lq]bell
shape\[rq].
.PP
[IMAGE: image (135de2b4d3cb1b1a3ece741c584c0a59.png)]
.SS \f[I]wt\f[]
.PP
The dataset has \f[I]32\f[] observations with \f[I]32\f[] valid values
(missing: \f[I]0\f[]) in \f[I]wt\f[].
This variable seems to be numeric.
.SS Base statistics
.PP
.TS
tab(@);
l l l l.
T{
\f[B]value\f[]
T}@T{
\f[B]mean(wt)\f[]
T}@T{
\f[B]sd(wt)\f[]
T}@T{
\f[B]var(wt)\f[]
T}
_
T{
(all)
T}@T{
3.2172
T}@T{
0.9785
T}@T{
0.9574
T}
.TE
.SS Histogram
.PP
[IMAGE: image (10caa8222b28328a6d8fd28917cbfb45.png)]
.PP
It seems that the highest value is \f[I]5.424\f[] which is exactly
3.5849 times higher than the smallest value (\f[I]1.513\f[]).
.PP
The standard deviation is 0.9785 (variance: 0.9574).
The expected value is around 3.2172, somewhere between 2.8782 and 3.5563
(SE: 0.173).
.PP
If we suppose that \f[I]wt\f[] is not near to a normal distribution
(test: see below, skewness: 0.4438, kurtosis: 3.1725), checking the
median (3.325) might be a better option instead of the mean.
The interquartile range (1.0288) measures the statistics dispersion of
the variable (similar to standard deviation) based on median.
.SS Normality tests
.SS Introduction
.PP
In statistics, \f[I]normality\f[] refers to an assumption that the
distribution of a random variable follows \f[I]normal\f[]
(\f[I]Gaussian\f[]) distribution.
Because of its bell-like shape, it's also known as the \f[I]\[lq]bell
curve\[rq]\f[].
The formula for \f[I]normal distribution\f[] is:
.PP
.RS
$f(x) = \\frac{1}{\\sqrt{2\\pi{}\\sigma{}^2}} e^{-\\frac{(x-\\mu{})^2}{2\\sigma{}^2}}$
.RE
.PP
\f[I]Normal distribution\f[] belongs to a \f[I]location-scale family\f[]
of distributions, as it's defined two parameters:
.IP \[bu] 2
\f[I]μ\f[] - \f[I]mean\f[] or \f[I]expectation\f[] (location parameter)
.IP \[bu] 2
\f[I]σ^2^\f[] - \f[I]variance\f[] (scale parameter)
.PP
[IMAGE: image (2f8c434e103f36ec70966b372838d448.png)]
.SS Normality Tests
.SS Overview
.PP
Various hypothesis tests can be applied in order to test if the
distribution of given random variable violates normality assumption.
These procedures test the H~0~ that provided variable's distribution is
\f[I]normal\f[].
At this point only few such tests will be covered: the ones that are
available in \f[C]stats\f[] package (which comes bundled with default R
installation) and \f[C]nortest\f[] package that is
available (http://cran.r-project.org/web/packages/nortest/index.html) on
CRAN.
.IP \[bu] 2
\f[B]Shapiro-Wilk test\f[] is a powerful normality test appropriate for
small samples.
In R, it's implemented in \f[C]shapiro.test\f[] function available in
\f[C]stats\f[] package.
.IP \[bu] 2
\f[B]Lilliefors test\f[] is a modification of \f[I]Kolmogorov-Smirnov
test\f[] appropriate for testing normality when parameters or normal
distribution (\f[I]μ\f[], \f[I]σ^2^\f[]) are not known.
\f[C]lillie.test\f[] function is located in \f[C]nortest\f[] package.
.IP \[bu] 2
\f[B]Anderson-Darling test\f[] is one of the most powerful normality
tests as it will detect the most of departures from normality.
You can find \f[C]ad.test\f[] function in \f[C]nortest\f[] package.
.IP \[bu] 2
\f[B]Pearson Χ^2^ test\f[] is another normality test which takes more
\[lq]traditional\[rq] approach in normality testing.
\f[C]pearson.test\f[] is located in \f[C]nortest\f[] package.
.SS Results
.PP
Here you can see the results of applied normality tests
(\f[I]p-values\f[] less than 0.05 indicate significant discrepancies):
.PP
.TS
tab(@);
l l l.
T{
T}@T{
\f[B]H\f[]
T}@T{
\f[B]p\f[]
T}
_
T{
shapiro.test
T}@T{
0.9433
T}@T{
0.0927
T}
T{
lillie.test
T}@T{
0.1356
T}@T{
0.1412
T}
T{
ad.test
T}@T{
0.6091
T}@T{
0.1038
T}
T{
pearson.test
T}@T{
4.5
T}@T{
0.4799
T}
.TE
.PP
So, let's draw some conclusions based on applied normality test:
.IP \[bu] 2
according to \f[I]Shapiro-Wilk test\f[], the distribution of \f[I]wt\f[]
is normal.
.IP \[bu] 2
based on \f[I]Lilliefors test\f[], distribution of \f[I]wt\f[] is not
normal
.IP \[bu] 2
\f[I]Anderson-Darling test\f[] confirms normality assumption
.IP \[bu] 2
\f[I]Pearson's Χ^2^ test\f[] classifies the underlying distribution as
non-normal
.SS Diagnostic Plots
.PP
There are various plots that can help you decide about the normality of
the distribution.
Only a few most commonly used plots will be shown: \f[I]histogram\f[],
\f[I]Q-Q plot\f[] and \f[I]kernel density plot\f[].
.SS Histogram
.PP
\f[I]Histogram\f[] was first introduced by \f[I]Karl Pearson\f[] and
it's probably the most popular plot for depicting the probability
distribution of a random variable.
However, the decision depends on number of bins, so it can sometimes be
misleading.
If the variable distribution is normal, bins should resemble the
\[lq]bell-like\[rq] shape.
.PP
[IMAGE: image (10caa8222b28328a6d8fd28917cbfb45.png)]
.SS Q-Q Plot
.PP
\[lq]Q\[rq] in \f[I]Q-Q plot\f[] stands for \f[I]quantile\f[], as this
plot compares empirical and theoretical distribution (in this case,
\f[I]normal\f[] distribution) by plotting their quantiles against each
other.
For normal distribution, plotted dots should approximate a
\[lq]straight\[rq], \f[C]x\ =\ y\f[] line.
.PP
[IMAGE: image (ff471a5bcb80aaf91b4c053ab038d69a.png)]
.SS Kernel Density Plot
.PP
\f[I]Kernel density plot\f[] is a plot of smoothed \f[I]empirical
distribution function\f[].
As such, it provides good insight about the shape of the distribution.
For normal distributions, it should resemble the well known \[lq]bell
shape\[rq].
.PP
[IMAGE: image (16a7d5cf96ceceffd6db59f9a2514dce.png)]
.PP
   *   *   *   *   *
.PP
This report was generated with rapport (http://rapport-package.info/).
.PP
[IMAGE: image (images/rapport.png)]
.SH AUTHORS
Rapport package team \@ https://github.com/aL3xa/rapport.
